{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfjob.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/oksL71r1RP0Rk4XcaqQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josepholaidepetro/tensorflow_job/blob/main/tfjob.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr9HhwtA28DV"
      },
      "source": [
        "JOB_FILE = \"tfjob.py\"\r\n",
        "TFJOB_YAML_FILE = \"tfjob.yaml\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoC76Vf_4ggR"
      },
      "source": [
        "**PYTHON SCRIPT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBRst6tJh2T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6900910-7654-428d-fca9-76ce946b51b5"
      },
      "source": [
        "%%writefile $JOB_FILE\r\n",
        "import argparse\r\n",
        "import json\r\n",
        "import os\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\r\n",
        "\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers, models\r\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def make_datasets_unbatched():\r\n",
        "  BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "  # Scaling MNIST data from (0, 255] to (0., 1.]\r\n",
        "  def scale(image, label):\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image /= 255\r\n",
        "    return image, label\r\n",
        "\r\n",
        "  datasets, _ = tfds.load(name='fashion_mnist', with_info=True, as_supervised=True)\r\n",
        "\r\n",
        "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)\r\n",
        "\r\n",
        "\r\n",
        "def model(args):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(\r\n",
        "      layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(256, activation='relu'))\r\n",
        "  model.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "  opt = args.optimizer\r\n",
        "  model.compile(optimizer=opt,\r\n",
        "                loss='sparse_categorical_crossentropy',\r\n",
        "                metrics=['accuracy'])\r\n",
        "  K.set_value(model.optimizer.learning_rate, args.learning_rate)\r\n",
        "  return model\r\n",
        "\r\n",
        "\r\n",
        "def main(args):\r\n",
        "\r\n",
        "  # MultiWorkerMirroredStrategy creates copies of all variables in the model's\r\n",
        "  # layers on each device across all workers\r\n",
        "  # if your GPUs don't support NCCL, replace \"communication\" with another\r\n",
        "  strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy(\r\n",
        "      communication=tf.distribute.experimental.CollectiveCommunication.AUTO)\r\n",
        "\r\n",
        "  BATCH_SIZE_PER_REPLICA = 64\r\n",
        "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n",
        "\r\n",
        "  with strategy.scope():\r\n",
        "    ds_train = make_datasets_unbatched().batch(BATCH_SIZE).repeat()\r\n",
        "    options = tf.data.Options()\r\n",
        "    options.experimental_distribute.auto_shard_policy = \\\r\n",
        "        tf.data.experimental.AutoShardPolicy.DATA\r\n",
        "\r\n",
        "    ds_train = ds_train.with_options(options)\r\n",
        "    # Model building/compiling need to be within `strategy.scope()`.\r\n",
        "    multi_worker_model = model(args)\r\n",
        "\r\n",
        "  # Callback for printing the LR at the end of each epoch.\r\n",
        "  class PrintLR(tf.keras.callbacks.Callback):\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs=None): #pylint: disable=no-self-use\r\n",
        "      print('\\nLearning rate for epoch {} is {}'.format(\r\n",
        "        epoch + 1, multi_worker_model.optimizer.lr.numpy()))\r\n",
        "\r\n",
        "  callbacks = [\r\n",
        "      tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n",
        "      PrintLR()\r\n",
        "   ]\r\n",
        "\r\n",
        "  # Keras' `model.fit()` trains the model with specified number of epochs and\r\n",
        "  # number of steps per epoch. Note that the numbers here are for demonstration\r\n",
        "  # purposes only and may not sufficiently produce a model with good quality.\r\n",
        "  multi_worker_model.fit(ds_train,\r\n",
        "                         epochs=10,\r\n",
        "                         steps_per_epoch=70,\r\n",
        "                         callbacks=callbacks)\r\n",
        "\r\n",
        "  # Saving a model\r\n",
        "  model_path = args.saved_model_dir\r\n",
        "\r\n",
        "  multi_worker_model.save(model_path)\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "  parser = argparse.ArgumentParser()\r\n",
        "  parser.add_argument('--saved_model_dir',\r\n",
        "                      type=str,\r\n",
        "                      required=True,\r\n",
        "                      help='Tensorflow export directory.')\r\n",
        "  parser.add_argument('--learning_rate', type=float,  required=True, default=0.001,\r\n",
        "                      help='Initial learning rate')\r\n",
        "  parser.add_argument('--optimizer', type=str, required=True, default='adam',\r\n",
        "                      help='optimizer')\r\n",
        "\r\n",
        "  parsed_args = parser.parse_args()\r\n",
        "  main(parsed_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing tfjob.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aroDwyHw4XgG"
      },
      "source": [
        "# **YAML FILE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qKDSBnSxY6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1e844f-e2cb-429c-ce23-7e7558ce2f99"
      },
      "source": [
        "%%writefile $TFJOB_YAML_FILE\r\n",
        "apiVersion: \"kubeflow.org/v1\"\r\n",
        "kind: \"TFJob\"\r\n",
        "metadata:\r\n",
        "  name: \"fmnist\"\r\n",
        "  namespace: josephadmin # your-user-namespace\r\n",
        "spec:\r\n",
        "  cleanPodPolicy: None\r\n",
        "  tfReplicaSpecs:\r\n",
        "    Worker:\r\n",
        "      replicas: 3\r\n",
        "      restartPolicy: OnFailure\r\n",
        "      template:\r\n",
        "        metadata:\r\n",
        "          annotations:\r\n",
        "            sidecar.istio.io/inject: \"false\"\r\n",
        "        spec:\r\n",
        "          containers:\r\n",
        "          - name: tensorflow\r\n",
        "            image: mavencodev/tfjob:6.0\r\n",
        "            command:\r\n",
        "                - \"python\"\r\n",
        "                - \"/tfjob.py\"\r\n",
        "                - \"--saved_model_dir=/train/saved_model/\"\r\n",
        "                - \"--learning_rate=0.001\"\r\n",
        "                - \"--optimizer=adam\"\r\n",
        "            volumeMounts:\r\n",
        "                - mountPath: \"/train\"\r\n",
        "                  name: \"training\"\r\n",
        "          volumes:\r\n",
        "            - name: \"training\"\r\n",
        "              persistentVolumeClaim:\r\n",
        "                claimName: \"tfevent-volume\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing tfjob.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zy0dMzx80tO"
      },
      "source": [
        "# **PERSISTENT VOLUME FILES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Anl7nW9UaX"
      },
      "source": [
        "PV = \"tfevent-pv.yaml\"\r\n",
        "PVC = \"tfevent-pvC.yaml\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G61Ohrfk9AUO",
        "outputId": "0fd8bf69-5cd1-45df-ef81-3c23f78cb985"
      },
      "source": [
        "%%writefile $PV\r\n",
        "apiVersion: v1\r\n",
        "kind: PersistentVolume\r\n",
        "metadata:\r\n",
        "  name: tfevent-volume\r\n",
        "  labels:\r\n",
        "    type: local\r\n",
        "    app: tfjob\r\n",
        "spec:\r\n",
        "  capacity:\r\n",
        "    storage: 10Gi\r\n",
        "  storageClassName: standard  \r\n",
        "  accessModes:\r\n",
        "    - ReadWriteMany\r\n",
        "  hostPath:\r\n",
        "    path: /tmp/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing tfevent-pv.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTsVwdWm9nTS",
        "outputId": "be95e4b9-1efc-4263-b8b2-001d22720e6e"
      },
      "source": [
        "%%writefile $PVC\r\n",
        "apiVersion: v1\r\n",
        "kind: PersistentVolumeClaim\r\n",
        "metadata:\r\n",
        "  name: tfevent-volume\r\n",
        "  namespace: josephadmin \r\n",
        "  labels:\r\n",
        "    type: local\r\n",
        "    app: tfjob\r\n",
        "spec:\r\n",
        "  accessModes:\r\n",
        "    - ReadWriteMany\r\n",
        "  resources:\r\n",
        "    requests:\r\n",
        "      storage: 10Gi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing tfevent-pvC.yaml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SD3m3bo_k8J"
      },
      "source": [
        "# Put all these files inside a Github repository"
      ]
    }
  ]
}